{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:05.773610Z",
     "start_time": "2024-05-31T08:46:03.475196Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_feature_extraction_files(directory):\n",
    "    \"\"\"\n",
    "    Searches for 'feature_extraction.csv' files within each subdirectory of a given directory.\n",
    "    \n",
    "    Args:\n",
    "    directory (str): The path to the directory to search within.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of full paths to each 'feature_extraction.csv' file found.\n",
    "    \"\"\"\n",
    "    csv_files = []\n",
    "    # Walk through each subdirectory in the provided directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        # Check if 'feature_extraction.csv' is in the files list\n",
    "        if 'feature_extraction.csv' in files:\n",
    "            # Construct full path and add to the list\n",
    "            full_path = os.path.join(root, 'feature_extraction.csv')\n",
    "            csv_files.append(full_path)\n",
    "            \n",
    "    return csv_files\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:05.779112Z",
     "start_time": "2024-05-31T08:46:05.774613Z"
    }
   },
   "id": "28e9436a6188da87",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def read_csv(data_file_path):\n",
    "    \n",
    "    df_read_file = pd.read_csv(data_file_path)\n",
    "    df_Acc = df_read_file.loc[:, :\"Label\"]\n",
    "    X_data = df_Acc.to_numpy()\n",
    "    \n",
    "    y_data = df_read_file.loc[:,\"Label\"]\n",
    "    y_data = np.around(y_data, decimals=0)\n",
    "\n",
    "    return X_data, y_data\n",
    "\n",
    "def normalize_positions(data):\n",
    "    posX_columns = [0] + list(range(4, 22))   # Adjusted for 0-based indexing: Columns 0 and 4 to 21 for PosX normalization\n",
    "    posY_columns = [1] + list(range(22, 39))  # Adjusted for 0-based indexing: Columns 1 and 22 to 38 for PosY normalization\n",
    "    \n",
    "    # Normalize PosX columns\n",
    "    data[:, posX_columns] = data[:, posX_columns] / 1920\n",
    "    # Normalize PosY columns\n",
    "    data[:, posY_columns] = data[:, posY_columns] / 1080\n",
    "            \n",
    "    return data\n",
    "\n",
    "def handle_indices(data, indexes_of_labels, label_value=0, label_col=0):\n",
    "    # Ensure data is a single column NumPy array\n",
    "    data = data[:, label_col] if data.ndim > 1 else data\n",
    "    \n",
    "\n",
    "    found_indexes = set(indexes_of_labels)  # Using a set to avoid duplicates\n",
    "\n",
    "    if indexes_of_labels:\n",
    "        # Handling '0' label exactly 3 lines before the first label\n",
    "        first_label_index = indexes_of_labels[0]\n",
    "        target_index_before_first = first_label_index - 3\n",
    "        if 0 <= target_index_before_first < len(data) and data[target_index_before_first] == label_value:\n",
    "            found_indexes.add(target_index_before_first)\n",
    "\n",
    "        # Handling '0' label exactly 3 lines after the last label\n",
    "        last_label_index = indexes_of_labels[-1]\n",
    "        target_index_after_last = last_label_index + 3\n",
    "        if 0 <= target_index_after_last < len(data) and data[target_index_after_last] == label_value:\n",
    "            found_indexes.add(target_index_after_last)\n",
    "\n",
    "        # Handling the '0' label in the middle between given label indices\n",
    "        for i in range(len(indexes_of_labels) - 1):\n",
    "            start_index = indexes_of_labels[i]\n",
    "            end_index = indexes_of_labels[i + 1]\n",
    "            middle_index = (start_index + end_index) // 2\n",
    "            if data[middle_index] == label_value:\n",
    "                found_indexes.add(middle_index)\n",
    "\n",
    "    # Convert set to a sorted list\n",
    "    sorted_indexes = sorted(found_indexes)\n",
    "    \n",
    "    return sorted_indexes\n",
    "\n",
    "\n",
    "def lstm_data_transform(x_data, y_data, keys, num_steps=6):\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    # Loop over the provided end indexes\n",
    "    for end_ix in keys:\n",
    "        # Calculate the start index for the current window\n",
    "        start_ix = end_ix - num_steps + 1\n",
    "        \n",
    "        # Ensure the start index is not negative\n",
    "        if start_ix < 0:\n",
    "            continue\n",
    "        \n",
    "        # Get a sequence of data for x\n",
    "        seq_X = x_data[start_ix:end_ix + 1, :-1]\n",
    "        \n",
    "        # Check if the sequence has the correct number of steps\n",
    "        if seq_X.shape[0] == num_steps:\n",
    "\n",
    "            # Append the sequence and target to the lists\n",
    "            X.append(seq_X)\n",
    "    \n",
    "    # Convert the lists to numpy arrays\n",
    "    x_array = np.array(X)\n",
    "    y_array = np.array([0, 1, 0, 2, 0, 3, 0, 4, 0, 5, 0])\n",
    "    \n",
    "    return x_array, y_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:05.789127Z",
     "start_time": "2024-05-31T08:46:05.780148Z"
    }
   },
   "id": "da493681d88ab4cd",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_relevant_rows(csv_path):\n",
    "    x_array, y_array = read_csv(csv_path)\n",
    "    \n",
    "    # Normalize the position columns\n",
    "    x_array = normalize_positions(x_array)\n",
    "\n",
    "    # Define the values to check\n",
    "    values_to_check = {1, 2, 3, 4, 5}\n",
    "\n",
    "    # Find the indexes of values in y_array that are in values_to_check\n",
    "    indexes_of_labels = [index for index, value in enumerate(y_array) if value in values_to_check]\n",
    "\n",
    "    sorted_indices = handle_indices(y_array, indexes_of_labels)\n",
    "    \n",
    "    # print('Sorted indices: ', sorted_indices)\n",
    "    \n",
    "    if len(sorted_indices) <= 10:\n",
    "        \n",
    "        print(csv_path)\n",
    "\n",
    "    x_data, y_data = lstm_data_transform(x_array, y_array, sorted_indices, num_steps=6)\n",
    "\n",
    "    return x_data, y_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:05.794023Z",
     "start_time": "2024-05-31T08:46:05.790180Z"
    }
   },
   "id": "578cb930756e4b7b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n"
     ]
    }
   ],
   "source": [
    "# Example of how to call this function for one CSV file\n",
    "file_paths = find_feature_extraction_files('Frames')\n",
    "\n",
    "print(len(file_paths))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:05.881886Z",
     "start_time": "2024-05-31T08:46:05.796026Z"
    }
   },
   "id": "62f0c3905190c28f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3817, 6, 55)\n",
      "(3817,)\n"
     ]
    }
   ],
   "source": [
    "num_of_steps = 6\n",
    "num_of_input_signals = 55\n",
    "\n",
    "X_data = np.empty([0, num_of_steps, num_of_input_signals], dtype=\"float32\")\n",
    "y_data = np.empty([0], dtype=\"float32\")\n",
    "\n",
    "for file_path in file_paths:\n",
    "    \n",
    "    data, labels = extract_relevant_rows(file_path)\n",
    "    \n",
    "    # print(labels.shape)\n",
    "    \n",
    "    X_data = np.append(X_data, data[:], axis=0)\n",
    "    \n",
    "    # print(labels.shape)\n",
    "    y_data = np.append(y_data, labels, axis=0)\n",
    "    \n",
    "print(X_data.shape)   # This should show (x, 6, 55) if  everything is correctly configured\n",
    "print(y_data.shape)  \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.249576Z",
     "start_time": "2024-05-31T08:46:05.882889Z"
    }
   },
   "id": "fb4673351a70bbe6",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def one_hot_encode_labels(y_data):\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    y_data_encoded = encoder.fit_transform(y_data)\n",
    "\n",
    "    return y_data_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.253221Z",
     "start_time": "2024-05-31T08:46:07.249576Z"
    }
   },
   "id": "c8e58440bc43804c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n",
      "y_data shape: (3817, 6)\n"
     ]
    }
   ],
   "source": [
    "# # # One-hot encode the labels\n",
    "# final_labels_encoded = one_hot_encode_labels(y_data.reshape(-1,1))\n",
    "\n",
    "final_labels_encoded = keras.utils.to_categorical(y_data, num_classes=6)\n",
    "\n",
    "print(final_labels_encoded)\n",
    "\n",
    "# print('x_data shape:', final_data.shape)\n",
    "print('y_data shape:', final_labels_encoded.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.258753Z",
     "start_time": "2024-05-31T08:46:07.254252Z"
    }
   },
   "id": "bf8044007422d6cc",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (3091, 6, 55)\n",
      "Train labels shape: (3091, 6)\n",
      "------------------------------------\n",
      "\n",
      "Test data shape: (382, 6, 55)\n",
      "Test labels shape: (382, 6)\n",
      "------------------------------------\n",
      "\n",
      "Validation data shape: (344, 6, 55)\n",
      "Validation labels shape: (344, 6)\n"
     ]
    }
   ],
   "source": [
    "# splits = custom_k_fold_split(x_data_flat, y_data_flat, n_splits=5, window_size=num_of_steps)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.10, random_state=42)\n",
    "    \n",
    "for train_index, test_index in sss.split(X_data, y_data): \n",
    "    X_train_pre, X_test = X_data[train_index], X_data[test_index] \n",
    "    y_train_pre, y_test = final_labels_encoded[train_index], final_labels_encoded[test_index] \n",
    "    \n",
    "for train_index, val_index in sss.split(X_train_pre, y_train_pre):\n",
    "    X_train, X_val = X_train_pre[train_index], X_train_pre[val_index] \n",
    "    y_train, y_val = y_train_pre[train_index], y_train_pre[val_index] \n",
    "\n",
    "# y_test.resize(y_test.shape[0],1,y_test.shape[1])\n",
    "# y_train.resize(y_train.shape[0],1, y_train.shape[1])\n",
    "# y_val.resize(y_val.shape[0],1, y_val.shape[1])\n",
    "    \n",
    "print(\"Train data shape:\", X_train.shape)\n",
    "print(\"Train labels shape:\", y_train.shape)\n",
    "print(\"------------------------------------\\n\")\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)\n",
    "print(\"------------------------------------\\n\")\n",
    "print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Validation labels shape:\", y_val.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.327723Z",
     "start_time": "2024-05-31T08:46:07.259764Z"
    }
   },
   "id": "fd4990ecf7cc8cf8",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, RMSprop \n",
    "\n",
    "from tensorflow.keras.regularizers import l1_l2, l2\n",
    "\n",
    "########################################################\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, Dense, InputLayer, Reshape, TimeDistributed, Dropout, BatchNormalization, Bidirectional\n",
    "\n",
    "# Define the CNN-LSTM model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Input layer - assumes input_shape is defined appropriately for your data\n",
    "# For example, input_shape could be (sequence_length, features_per_step)\n",
    "model.add(InputLayer(shape=(6, 55)))\n",
    "# Batch Normalization layer before LSTM to normalize inputs\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Adding a Bidirectional LSTM layer with L2 regularization\n",
    "# Note: Adjust the `l2` regularization strength as needed\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True, dropout=0.3, recurrent_dropout=0.3, kernel_regularizer=l1_l2(l1=1e-5, l2=0.001))))\n",
    "# Adding another Bidirectional LSTM layer\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=False, dropout=0.3,recurrent_dropout=0.3)))\n",
    "\n",
    "# Output layer - assuming a classification problem with 6 classes\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# model.add(InputLayer(shape=(6, 55)))\n",
    "# model.add(Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))\n",
    "# model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))\n",
    "# \n",
    "# # Ensure the kernel size is smaller than the sequence length\n",
    "# model.add(Conv1D(32, 5, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=1))  # Reduce the sequence length by a factor of 2\n",
    "# model.add(Conv1D(16, 2, activation='relu'))\n",
    "# \n",
    "# # Since MaxPooling1D and Conv1D layers have reduced the sequence length, we need to adjust for the LSTM layer\n",
    "# model.add(LSTM(16, activation='tanh', return_sequences=True))\n",
    "# model.add(Dropout(0.5))\n",
    "# \n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(6, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.444775Z",
     "start_time": "2024-05-31T08:46:07.328722Z"
    }
   },
   "id": "60465be6f3b2ac2a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# from collections import Counter\n",
    "# y_train_integers = np.argmax(y_train, axis=1)\n",
    "# \n",
    "# class_counts = Counter(y_train_integers)\n",
    "# total_samples = sum(class_counts.values())\n",
    "# class_frequencies = {k: v / total_samples for k, v in class_counts.items()}\n",
    "# print(class_frequencies) \n",
    "# \n",
    "# class_weights = {class_id: 1.0 / freq for class_id, freq in class_frequencies.items()}\n",
    "# \n",
    "# weight_total = sum(class_weights.values())\n",
    "# normalized_class_weights = {class_id: weight * len(class_weights) / weight_total for class_id, weight in class_weights.items()}\n",
    "# \n",
    "# #normalized_class_weights[0] = 0.4  # Adjust this based on your specific needs, perhaps even higher\n",
    "# \n",
    "# print('Class weights: ', normalized_class_weights)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.448796Z",
     "start_time": "2024-05-31T08:46:07.444775Z"
    }
   },
   "id": "187bb074e8d28226",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# \n",
    "# print(y_train.shape)\n",
    "# \n",
    "# if y_train.shape[1] == 1:\n",
    "#     y_squeezed = np.squeeze(y_train, axis=1)\n",
    "#     y_weighted = np.argmax(y_squeezed, axis=1)\n",
    "# else:\n",
    "#     y_weighted = np.argmax(y_train, axis=1)\n",
    "# \n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(y_weighted), y=y_weighted)\n",
    "# \n",
    "# class_weight_dict = dict(enumerate(class_weights))\n",
    "# \n",
    "# print(class_weight_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.452948Z",
     "start_time": "2024-05-31T08:46:07.449803Z"
    }
   },
   "id": "af92cda95fa5d38d",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.464421Z",
     "start_time": "2024-05-31T08:46:07.453953Z"
    }
   },
   "id": "98b4440b35fecb69",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ batch_normalization             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m55\u001B[0m)          │           \u001B[38;5;34m220\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (\u001B[38;5;33mBidirectional\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m200\u001B[0m)         │       \u001B[38;5;34m124,800\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (\u001B[38;5;33mBidirectional\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m)            │       \u001B[38;5;34m240,800\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │         \u001B[38;5;34m1,206\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">124,800</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,206</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m367,026\u001B[0m (1.40 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">367,026</span> (1.40 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m366,916\u001B[0m (1.40 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">366,916</span> (1.40 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m110\u001B[0m (440.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> (440.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.481459Z",
     "start_time": "2024-05-31T08:46:07.466422Z"
    }
   },
   "id": "999a2fb827c2b148",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.484907Z",
     "start_time": "2024-05-31T08:46:07.482462Z"
    }
   },
   "id": "6f6dfd6ee894f299",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.src.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "es_callback = EarlyStopping(monitor='val_loss', mode='min', patience=50, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:46:07.489405Z",
     "start_time": "2024-05-31T08:46:07.485910Z"
    }
   },
   "id": "3a0b94183492e344",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 12ms/step - accuracy: 0.4755 - loss: 1.4660 - val_accuracy: 0.5233 - val_loss: 1.8138 - learning_rate: 0.0010\n",
      "Epoch 2/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5728 - loss: 1.0910 - val_accuracy: 0.5436 - val_loss: 1.3201 - learning_rate: 0.0010\n",
      "Epoch 3/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6196 - loss: 0.9910 - val_accuracy: 0.5349 - val_loss: 1.2658 - learning_rate: 0.0010\n",
      "Epoch 4/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6088 - loss: 0.9490 - val_accuracy: 0.6105 - val_loss: 1.0209 - learning_rate: 0.0010\n",
      "Epoch 5/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6496 - loss: 0.9005 - val_accuracy: 0.5581 - val_loss: 0.9848 - learning_rate: 0.0010\n",
      "Epoch 6/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6545 - loss: 0.8473 - val_accuracy: 0.6308 - val_loss: 0.9156 - learning_rate: 0.0010\n",
      "Epoch 7/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6395 - loss: 0.8410 - val_accuracy: 0.6395 - val_loss: 0.9374 - learning_rate: 0.0010\n",
      "Epoch 8/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6397 - loss: 0.8324 - val_accuracy: 0.6599 - val_loss: 0.8510 - learning_rate: 0.0010\n",
      "Epoch 9/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6449 - loss: 0.8305 - val_accuracy: 0.6570 - val_loss: 0.8515 - learning_rate: 0.0010\n",
      "Epoch 10/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6622 - loss: 0.8165 - val_accuracy: 0.6715 - val_loss: 0.8176 - learning_rate: 0.0010\n",
      "Epoch 11/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6335 - loss: 0.8087 - val_accuracy: 0.6599 - val_loss: 0.8318 - learning_rate: 0.0010\n",
      "Epoch 12/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6655 - loss: 0.7631 - val_accuracy: 0.6744 - val_loss: 0.7862 - learning_rate: 0.0010\n",
      "Epoch 13/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6888 - loss: 0.7326 - val_accuracy: 0.6570 - val_loss: 0.8142 - learning_rate: 0.0010\n",
      "Epoch 14/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6677 - loss: 0.7738 - val_accuracy: 0.6628 - val_loss: 0.8064 - learning_rate: 0.0010\n",
      "Epoch 15/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6633 - loss: 0.7573 - val_accuracy: 0.6570 - val_loss: 0.7946 - learning_rate: 0.0010\n",
      "Epoch 16/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6816 - loss: 0.7169 - val_accuracy: 0.6715 - val_loss: 0.7913 - learning_rate: 0.0010\n",
      "Epoch 17/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6671 - loss: 0.7321 - val_accuracy: 0.6802 - val_loss: 0.7544 - learning_rate: 0.0010\n",
      "Epoch 18/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6974 - loss: 0.7109 - val_accuracy: 0.6744 - val_loss: 0.7755 - learning_rate: 0.0010\n",
      "Epoch 19/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6912 - loss: 0.6901 - val_accuracy: 0.6686 - val_loss: 0.7830 - learning_rate: 0.0010\n",
      "Epoch 20/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6737 - loss: 0.7163 - val_accuracy: 0.7151 - val_loss: 0.7817 - learning_rate: 0.0010\n",
      "Epoch 21/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6877 - loss: 0.7010 - val_accuracy: 0.7064 - val_loss: 0.7626 - learning_rate: 0.0010\n",
      "Epoch 22/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6871 - loss: 0.7094 - val_accuracy: 0.7355 - val_loss: 0.7471 - learning_rate: 0.0010\n",
      "Epoch 23/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6876 - loss: 0.6877 - val_accuracy: 0.7238 - val_loss: 0.7338 - learning_rate: 0.0010\n",
      "Epoch 24/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.6980 - loss: 0.6781 - val_accuracy: 0.7093 - val_loss: 0.7354 - learning_rate: 0.0010\n",
      "Epoch 25/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7076 - loss: 0.6588 - val_accuracy: 0.6599 - val_loss: 0.7731 - learning_rate: 0.0010\n",
      "Epoch 26/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7184 - loss: 0.6541 - val_accuracy: 0.6802 - val_loss: 0.7433 - learning_rate: 0.0010\n",
      "Epoch 27/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7054 - loss: 0.6858 - val_accuracy: 0.7413 - val_loss: 0.7337 - learning_rate: 0.0010\n",
      "Epoch 28/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7097 - loss: 0.6570 - val_accuracy: 0.7064 - val_loss: 0.7671 - learning_rate: 0.0010\n",
      "Epoch 29/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7219 - loss: 0.6494 - val_accuracy: 0.6686 - val_loss: 0.7965 - learning_rate: 0.0010\n",
      "Epoch 30/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7193 - loss: 0.6611 - val_accuracy: 0.6890 - val_loss: 0.7901 - learning_rate: 0.0010\n",
      "Epoch 31/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7050 - loss: 0.6661 - val_accuracy: 0.7529 - val_loss: 0.7111 - learning_rate: 0.0010\n",
      "Epoch 32/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7005 - loss: 0.6699 - val_accuracy: 0.7645 - val_loss: 0.7052 - learning_rate: 0.0010\n",
      "Epoch 33/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7204 - loss: 0.6443 - val_accuracy: 0.7209 - val_loss: 0.7131 - learning_rate: 0.0010\n",
      "Epoch 34/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7341 - loss: 0.6172 - val_accuracy: 0.7645 - val_loss: 0.7202 - learning_rate: 0.0010\n",
      "Epoch 35/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7310 - loss: 0.6285 - val_accuracy: 0.7326 - val_loss: 0.7382 - learning_rate: 0.0010\n",
      "Epoch 36/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7270 - loss: 0.6397 - val_accuracy: 0.7413 - val_loss: 0.7159 - learning_rate: 0.0010\n",
      "Epoch 37/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7411 - loss: 0.6221 - val_accuracy: 0.7703 - val_loss: 0.7121 - learning_rate: 0.0010\n",
      "Epoch 38/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7219 - loss: 0.6446 - val_accuracy: 0.7180 - val_loss: 0.7282 - learning_rate: 0.0010\n",
      "Epoch 39/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7381 - loss: 0.6184 - val_accuracy: 0.7297 - val_loss: 0.7242 - learning_rate: 0.0010\n",
      "Epoch 40/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7305 - loss: 0.6212 - val_accuracy: 0.7297 - val_loss: 0.6858 - learning_rate: 0.0010\n",
      "Epoch 41/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7383 - loss: 0.6103 - val_accuracy: 0.7587 - val_loss: 0.6721 - learning_rate: 0.0010\n",
      "Epoch 42/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7395 - loss: 0.6176 - val_accuracy: 0.7355 - val_loss: 0.7027 - learning_rate: 0.0010\n",
      "Epoch 43/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7567 - loss: 0.6012 - val_accuracy: 0.7238 - val_loss: 0.6896 - learning_rate: 0.0010\n",
      "Epoch 44/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7474 - loss: 0.5838 - val_accuracy: 0.7297 - val_loss: 0.7032 - learning_rate: 0.0010\n",
      "Epoch 45/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7516 - loss: 0.5840 - val_accuracy: 0.7442 - val_loss: 0.6933 - learning_rate: 0.0010\n",
      "Epoch 46/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7363 - loss: 0.5980 - val_accuracy: 0.7064 - val_loss: 0.7353 - learning_rate: 0.0010\n",
      "Epoch 47/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7434 - loss: 0.5966 - val_accuracy: 0.7297 - val_loss: 0.6844 - learning_rate: 0.0010\n",
      "Epoch 48/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7212 - loss: 0.6382 - val_accuracy: 0.7151 - val_loss: 0.7139 - learning_rate: 0.0010\n",
      "Epoch 49/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7566 - loss: 0.5797 - val_accuracy: 0.7384 - val_loss: 0.7016 - learning_rate: 0.0010\n",
      "Epoch 50/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7541 - loss: 0.5783 - val_accuracy: 0.7355 - val_loss: 0.7127 - learning_rate: 0.0010\n",
      "Epoch 51/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7376 - loss: 0.5891 - val_accuracy: 0.7326 - val_loss: 0.6997 - learning_rate: 0.0010\n",
      "Epoch 52/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7571 - loss: 0.5975 - val_accuracy: 0.7180 - val_loss: 0.7130 - learning_rate: 0.0010\n",
      "Epoch 53/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7634 - loss: 0.5680 - val_accuracy: 0.7326 - val_loss: 0.6927 - learning_rate: 0.0010\n",
      "Epoch 54/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7454 - loss: 0.6049 - val_accuracy: 0.7849 - val_loss: 0.6744 - learning_rate: 0.0010\n",
      "Epoch 55/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7385 - loss: 0.5968 - val_accuracy: 0.7529 - val_loss: 0.6837 - learning_rate: 0.0010\n",
      "Epoch 56/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7414 - loss: 0.6032 - val_accuracy: 0.7703 - val_loss: 0.6801 - learning_rate: 0.0010\n",
      "Epoch 57/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7537 - loss: 0.5683 - val_accuracy: 0.7558 - val_loss: 0.6629 - learning_rate: 3.0000e-04\n",
      "Epoch 58/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7771 - loss: 0.5603 - val_accuracy: 0.7936 - val_loss: 0.6577 - learning_rate: 3.0000e-04\n",
      "Epoch 59/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7737 - loss: 0.5297 - val_accuracy: 0.7733 - val_loss: 0.6503 - learning_rate: 3.0000e-04\n",
      "Epoch 60/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7713 - loss: 0.5462 - val_accuracy: 0.7762 - val_loss: 0.6417 - learning_rate: 3.0000e-04\n",
      "Epoch 61/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7483 - loss: 0.5658 - val_accuracy: 0.7733 - val_loss: 0.6478 - learning_rate: 3.0000e-04\n",
      "Epoch 62/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7802 - loss: 0.5347 - val_accuracy: 0.7907 - val_loss: 0.6473 - learning_rate: 3.0000e-04\n",
      "Epoch 63/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7738 - loss: 0.5278 - val_accuracy: 0.7907 - val_loss: 0.6470 - learning_rate: 3.0000e-04\n",
      "Epoch 64/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7833 - loss: 0.5221 - val_accuracy: 0.7733 - val_loss: 0.6396 - learning_rate: 3.0000e-04\n",
      "Epoch 65/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7792 - loss: 0.5471 - val_accuracy: 0.7762 - val_loss: 0.6464 - learning_rate: 3.0000e-04\n",
      "Epoch 66/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7900 - loss: 0.5134 - val_accuracy: 0.7645 - val_loss: 0.6477 - learning_rate: 3.0000e-04\n",
      "Epoch 67/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7920 - loss: 0.5082 - val_accuracy: 0.7820 - val_loss: 0.6524 - learning_rate: 3.0000e-04\n",
      "Epoch 68/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7852 - loss: 0.5192 - val_accuracy: 0.7645 - val_loss: 0.6408 - learning_rate: 3.0000e-04\n",
      "Epoch 69/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7878 - loss: 0.5138 - val_accuracy: 0.7558 - val_loss: 0.6499 - learning_rate: 3.0000e-04\n",
      "Epoch 70/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8001 - loss: 0.4947 - val_accuracy: 0.7442 - val_loss: 0.6616 - learning_rate: 3.0000e-04\n",
      "Epoch 71/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7941 - loss: 0.5104 - val_accuracy: 0.7762 - val_loss: 0.6392 - learning_rate: 3.0000e-04\n",
      "Epoch 72/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7877 - loss: 0.5166 - val_accuracy: 0.7733 - val_loss: 0.6427 - learning_rate: 3.0000e-04\n",
      "Epoch 73/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7819 - loss: 0.5326 - val_accuracy: 0.7703 - val_loss: 0.6427 - learning_rate: 3.0000e-04\n",
      "Epoch 74/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7759 - loss: 0.5219 - val_accuracy: 0.7791 - val_loss: 0.6368 - learning_rate: 3.0000e-04\n",
      "Epoch 75/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7885 - loss: 0.5174 - val_accuracy: 0.7616 - val_loss: 0.6633 - learning_rate: 3.0000e-04\n",
      "Epoch 76/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7806 - loss: 0.5245 - val_accuracy: 0.7820 - val_loss: 0.6497 - learning_rate: 3.0000e-04\n",
      "Epoch 77/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7886 - loss: 0.5078 - val_accuracy: 0.7645 - val_loss: 0.6445 - learning_rate: 3.0000e-04\n",
      "Epoch 78/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7703 - loss: 0.5324 - val_accuracy: 0.7791 - val_loss: 0.6473 - learning_rate: 3.0000e-04\n",
      "Epoch 79/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7666 - loss: 0.5302 - val_accuracy: 0.7645 - val_loss: 0.6630 - learning_rate: 3.0000e-04\n",
      "Epoch 80/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7660 - loss: 0.5450 - val_accuracy: 0.7616 - val_loss: 0.6363 - learning_rate: 3.0000e-04\n",
      "Epoch 81/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8017 - loss: 0.5059 - val_accuracy: 0.7733 - val_loss: 0.6402 - learning_rate: 3.0000e-04\n",
      "Epoch 82/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7770 - loss: 0.5168 - val_accuracy: 0.7820 - val_loss: 0.6451 - learning_rate: 3.0000e-04\n",
      "Epoch 83/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7961 - loss: 0.5046 - val_accuracy: 0.7529 - val_loss: 0.6467 - learning_rate: 3.0000e-04\n",
      "Epoch 84/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7744 - loss: 0.5286 - val_accuracy: 0.7762 - val_loss: 0.6396 - learning_rate: 3.0000e-04\n",
      "Epoch 85/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7714 - loss: 0.5485 - val_accuracy: 0.7762 - val_loss: 0.6490 - learning_rate: 3.0000e-04\n",
      "Epoch 86/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8007 - loss: 0.4955 - val_accuracy: 0.7616 - val_loss: 0.6482 - learning_rate: 3.0000e-04\n",
      "Epoch 87/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7883 - loss: 0.5061 - val_accuracy: 0.7703 - val_loss: 0.6361 - learning_rate: 3.0000e-04\n",
      "Epoch 88/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7904 - loss: 0.4993 - val_accuracy: 0.7616 - val_loss: 0.6432 - learning_rate: 3.0000e-04\n",
      "Epoch 89/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7904 - loss: 0.4777 - val_accuracy: 0.7878 - val_loss: 0.6491 - learning_rate: 3.0000e-04\n",
      "Epoch 90/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7691 - loss: 0.5275 - val_accuracy: 0.7820 - val_loss: 0.6479 - learning_rate: 3.0000e-04\n",
      "Epoch 91/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7980 - loss: 0.4930 - val_accuracy: 0.7791 - val_loss: 0.6481 - learning_rate: 3.0000e-04\n",
      "Epoch 92/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7973 - loss: 0.4944 - val_accuracy: 0.7849 - val_loss: 0.6350 - learning_rate: 3.0000e-04\n",
      "Epoch 93/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7968 - loss: 0.5084 - val_accuracy: 0.7791 - val_loss: 0.6477 - learning_rate: 3.0000e-04\n",
      "Epoch 94/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7902 - loss: 0.5024 - val_accuracy: 0.7791 - val_loss: 0.6412 - learning_rate: 3.0000e-04\n",
      "Epoch 95/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7997 - loss: 0.4923 - val_accuracy: 0.7703 - val_loss: 0.6480 - learning_rate: 3.0000e-04\n",
      "Epoch 96/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8093 - loss: 0.4918 - val_accuracy: 0.7820 - val_loss: 0.6497 - learning_rate: 3.0000e-04\n",
      "Epoch 97/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7973 - loss: 0.4924 - val_accuracy: 0.7820 - val_loss: 0.6602 - learning_rate: 3.0000e-04\n",
      "Epoch 98/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7821 - loss: 0.4963 - val_accuracy: 0.7703 - val_loss: 0.6452 - learning_rate: 3.0000e-04\n",
      "Epoch 99/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7906 - loss: 0.4928 - val_accuracy: 0.7878 - val_loss: 0.6296 - learning_rate: 3.0000e-04\n",
      "Epoch 100/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7898 - loss: 0.5031 - val_accuracy: 0.7703 - val_loss: 0.6535 - learning_rate: 3.0000e-04\n",
      "Epoch 101/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7797 - loss: 0.5001 - val_accuracy: 0.7820 - val_loss: 0.6255 - learning_rate: 3.0000e-04\n",
      "Epoch 102/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7957 - loss: 0.4972 - val_accuracy: 0.7733 - val_loss: 0.6200 - learning_rate: 3.0000e-04\n",
      "Epoch 103/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7894 - loss: 0.5074 - val_accuracy: 0.7820 - val_loss: 0.6302 - learning_rate: 3.0000e-04\n",
      "Epoch 104/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7747 - loss: 0.5100 - val_accuracy: 0.7878 - val_loss: 0.6391 - learning_rate: 3.0000e-04\n",
      "Epoch 105/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7807 - loss: 0.5162 - val_accuracy: 0.7558 - val_loss: 0.6677 - learning_rate: 3.0000e-04\n",
      "Epoch 106/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7795 - loss: 0.5199 - val_accuracy: 0.7936 - val_loss: 0.6283 - learning_rate: 3.0000e-04\n",
      "Epoch 107/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7914 - loss: 0.4953 - val_accuracy: 0.7907 - val_loss: 0.6345 - learning_rate: 3.0000e-04\n",
      "Epoch 108/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7983 - loss: 0.4931 - val_accuracy: 0.7878 - val_loss: 0.6310 - learning_rate: 3.0000e-04\n",
      "Epoch 109/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7955 - loss: 0.4941 - val_accuracy: 0.7994 - val_loss: 0.6259 - learning_rate: 3.0000e-04\n",
      "Epoch 110/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7819 - loss: 0.4925 - val_accuracy: 0.7762 - val_loss: 0.6461 - learning_rate: 3.0000e-04\n",
      "Epoch 111/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7898 - loss: 0.4913 - val_accuracy: 0.7907 - val_loss: 0.6511 - learning_rate: 3.0000e-04\n",
      "Epoch 112/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7969 - loss: 0.4871 - val_accuracy: 0.7471 - val_loss: 0.6652 - learning_rate: 3.0000e-04\n",
      "Epoch 113/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7944 - loss: 0.4933 - val_accuracy: 0.7791 - val_loss: 0.6517 - learning_rate: 3.0000e-04\n",
      "Epoch 114/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7986 - loss: 0.5023 - val_accuracy: 0.7849 - val_loss: 0.6435 - learning_rate: 3.0000e-04\n",
      "Epoch 115/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8089 - loss: 0.4880 - val_accuracy: 0.7674 - val_loss: 0.6496 - learning_rate: 3.0000e-04\n",
      "Epoch 116/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7963 - loss: 0.4791 - val_accuracy: 0.7587 - val_loss: 0.6562 - learning_rate: 3.0000e-04\n",
      "Epoch 117/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7982 - loss: 0.4810 - val_accuracy: 0.7878 - val_loss: 0.6297 - learning_rate: 3.0000e-04\n",
      "Epoch 118/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7977 - loss: 0.4841 - val_accuracy: 0.7674 - val_loss: 0.6354 - learning_rate: 9.0000e-05\n",
      "Epoch 119/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8243 - loss: 0.4629 - val_accuracy: 0.7820 - val_loss: 0.6414 - learning_rate: 9.0000e-05\n",
      "Epoch 120/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8040 - loss: 0.4831 - val_accuracy: 0.7791 - val_loss: 0.6328 - learning_rate: 9.0000e-05\n",
      "Epoch 121/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8113 - loss: 0.4653 - val_accuracy: 0.7703 - val_loss: 0.6370 - learning_rate: 9.0000e-05\n",
      "Epoch 122/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8172 - loss: 0.4824 - val_accuracy: 0.7762 - val_loss: 0.6340 - learning_rate: 9.0000e-05\n",
      "Epoch 123/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8022 - loss: 0.4678 - val_accuracy: 0.7791 - val_loss: 0.6308 - learning_rate: 9.0000e-05\n",
      "Epoch 124/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8013 - loss: 0.4762 - val_accuracy: 0.7762 - val_loss: 0.6327 - learning_rate: 9.0000e-05\n",
      "Epoch 125/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8082 - loss: 0.4676 - val_accuracy: 0.7791 - val_loss: 0.6310 - learning_rate: 9.0000e-05\n",
      "Epoch 126/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7992 - loss: 0.4910 - val_accuracy: 0.7820 - val_loss: 0.6376 - learning_rate: 9.0000e-05\n",
      "Epoch 127/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8286 - loss: 0.4407 - val_accuracy: 0.7820 - val_loss: 0.6323 - learning_rate: 9.0000e-05\n",
      "Epoch 128/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8081 - loss: 0.4800 - val_accuracy: 0.7849 - val_loss: 0.6304 - learning_rate: 9.0000e-05\n",
      "Epoch 129/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8164 - loss: 0.4659 - val_accuracy: 0.7762 - val_loss: 0.6368 - learning_rate: 9.0000e-05\n",
      "Epoch 130/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8082 - loss: 0.4894 - val_accuracy: 0.7907 - val_loss: 0.6234 - learning_rate: 9.0000e-05\n",
      "Epoch 131/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8130 - loss: 0.4690 - val_accuracy: 0.7878 - val_loss: 0.6309 - learning_rate: 9.0000e-05\n",
      "Epoch 132/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7936 - loss: 0.4783 - val_accuracy: 0.7820 - val_loss: 0.6367 - learning_rate: 9.0000e-05\n",
      "Epoch 133/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8044 - loss: 0.4743 - val_accuracy: 0.7820 - val_loss: 0.6354 - learning_rate: 2.7000e-05\n",
      "Epoch 134/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8135 - loss: 0.4629 - val_accuracy: 0.7849 - val_loss: 0.6347 - learning_rate: 2.7000e-05\n",
      "Epoch 135/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7922 - loss: 0.4757 - val_accuracy: 0.7791 - val_loss: 0.6357 - learning_rate: 2.7000e-05\n",
      "Epoch 136/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8067 - loss: 0.4834 - val_accuracy: 0.7791 - val_loss: 0.6342 - learning_rate: 2.7000e-05\n",
      "Epoch 137/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8208 - loss: 0.4714 - val_accuracy: 0.7791 - val_loss: 0.6334 - learning_rate: 2.7000e-05\n",
      "Epoch 138/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8204 - loss: 0.4536 - val_accuracy: 0.7791 - val_loss: 0.6324 - learning_rate: 2.7000e-05\n",
      "Epoch 139/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8146 - loss: 0.4626 - val_accuracy: 0.7820 - val_loss: 0.6340 - learning_rate: 2.7000e-05\n",
      "Epoch 140/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8035 - loss: 0.4765 - val_accuracy: 0.7820 - val_loss: 0.6316 - learning_rate: 2.7000e-05\n",
      "Epoch 141/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8164 - loss: 0.4588 - val_accuracy: 0.7878 - val_loss: 0.6317 - learning_rate: 2.7000e-05\n",
      "Epoch 142/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7993 - loss: 0.4855 - val_accuracy: 0.7849 - val_loss: 0.6320 - learning_rate: 2.7000e-05\n",
      "Epoch 143/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8116 - loss: 0.4761 - val_accuracy: 0.7733 - val_loss: 0.6344 - learning_rate: 2.7000e-05\n",
      "Epoch 144/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8027 - loss: 0.4692 - val_accuracy: 0.7849 - val_loss: 0.6326 - learning_rate: 2.7000e-05\n",
      "Epoch 145/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8101 - loss: 0.4664 - val_accuracy: 0.7820 - val_loss: 0.6329 - learning_rate: 2.7000e-05\n",
      "Epoch 146/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8089 - loss: 0.4616 - val_accuracy: 0.7762 - val_loss: 0.6345 - learning_rate: 2.7000e-05\n",
      "Epoch 147/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8187 - loss: 0.4632 - val_accuracy: 0.7762 - val_loss: 0.6366 - learning_rate: 2.7000e-05\n",
      "Epoch 148/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8063 - loss: 0.4626 - val_accuracy: 0.7762 - val_loss: 0.6345 - learning_rate: 8.1000e-06\n",
      "Epoch 149/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8212 - loss: 0.4428 - val_accuracy: 0.7791 - val_loss: 0.6356 - learning_rate: 8.1000e-06\n",
      "Epoch 150/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8159 - loss: 0.4530 - val_accuracy: 0.7791 - val_loss: 0.6345 - learning_rate: 8.1000e-06\n",
      "Epoch 151/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8168 - loss: 0.4642 - val_accuracy: 0.7791 - val_loss: 0.6338 - learning_rate: 8.1000e-06\n",
      "Epoch 152/250\n",
      "\u001B[1m97/97\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8126 - loss: 0.4655 - val_accuracy: 0.7820 - val_loss: 0.6342 - learning_rate: 8.1000e-06\n",
      "Epoch 152: early stopping\n",
      "Restoring model weights from the end of the best epoch: 102.\n",
      "Model trained in 89.792382s.\n",
      "This is 1.496540min.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.benchmark import timer\n",
    "\n",
    "# fit the keras model on the dataset0\n",
    "startTime = timer()\n",
    "history = model.fit(X_train, y_train, epochs=250, callbacks=[es_callback, reduce_lr], validation_data=(X_val, y_val), batch_size=32, verbose=1)#, class_weight=class_weight_dict)\n",
    "\n",
    "endTime = timer()\n",
    "print(\"Model trained in {:f}s.\".format(endTime - startTime))\n",
    "print(\"This is {:f}min.\".format((endTime - startTime)/60))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:47:39.397881Z",
     "start_time": "2024-05-31T08:46:07.489405Z"
    }
   },
   "id": "c838c202efbda00f",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step \n",
      "Shape of predictions: (382, 6)\n",
      "Shape of y_test: (382, 6)\n",
      "Shape of predictions after reshaping: (382, 6)\n",
      "Shape of y_test after reshaping: (382, 6)\n",
      "Shape of predicted_classes: (382,)\n",
      "Shape of true_classes: (382,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming X_test and y_test are already defined and preprocessed\n",
    "# Predict on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Print the shapes to debug\n",
    "print(f\"Shape of predictions: {predictions.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "\n",
    "# # Reshape the predictions and y_test to remove the extra dimension\n",
    "# predictions = predictions.reshape(predictions.shape[0], predictions.shape[2])\n",
    "# y_test = y_test.reshape(y_test.shape[0], y_test.shape[2])\n",
    "\n",
    "# Print the shapes to debugs\n",
    "print(f\"Shape of predictions after reshaping: {predictions.shape}\")\n",
    "print(f\"Shape of y_test after reshaping: {y_test.shape}\")\n",
    "\n",
    "# Convert predictions and true labels to class indices\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print the shapes to debug\n",
    "print(f\"Shape of predicted_classes: {predicted_classes.shape}\")\n",
    "print(f\"Shape of true_classes: {true_classes.shape}\")\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:47:49.785749Z",
     "start_time": "2024-05-31T08:47:49.502474Z"
    }
   },
   "id": "4882a101ec9de4f2",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:47:40.820740Z",
     "start_time": "2024-05-31T08:47:40.817570Z"
    }
   },
   "id": "652e0a1f124c745c",
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
